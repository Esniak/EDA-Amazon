{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importar las librerías necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan, het_white\n",
        "\n",
        "# Paso 1: Importar el dataset\n",
        "amazon_correl = pd.read_csv(r'/content/amazon_dataset_final.csv')\n",
        "\n",
        "# Paso 2: Selección de características y variable objetivo (solo 'actual_price')\n",
        "X = amazon_correl[['actual_price']]\n",
        "Y = amazon_correl['discounted_price']\n",
        "\n",
        "# Paso 3: Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nNúmero de observaciones en entrenamiento: {X_train.shape[0]}\")\n",
        "print(f\"Número de observaciones en prueba: {X_test.shape[0]}\")\n",
        "\n",
        "# Agregar una constante (intercepto) al modelo\n",
        "X_train_const = sm.add_constant(X_train)\n",
        "X_test_const = sm.add_constant(X_test)\n",
        "\n",
        "# Paso 4: Calcular el VIF para cada variable predictora en el conjunto de entrenamiento\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = X_train_const.columns\n",
        "vif_data[\"VIF\"] = [\n",
        "    variance_inflation_factor(X_train_const.values, i)\n",
        "    for i in range(X_train_const.shape[1])\n",
        "]\n",
        "\n",
        "# Mostrar los valores de VIF\n",
        "print(\"\\nValores de VIF para cada variable predictora (Entrenamiento):\")\n",
        "print(vif_data)\n",
        "\n",
        "# Paso 5: Ajustar el modelo de regresión lineal (OLS) en el conjunto de entrenamiento\n",
        "model_ols = sm.OLS(Y_train, X_train_const).fit()\n",
        "\n",
        "# Ajustar el modelo con errores estándar robustos (HC3)\n",
        "model_robust = model_ols.get_robustcov_results(cov_type='HC3')\n",
        "\n",
        "# Mostrar el resumen del modelo robusto\n",
        "print(\"\\nResumen del modelo de regresión lineal con errores estándar robustos (HC3) - Entrenamiento:\")\n",
        "print(model_robust.summary())\n",
        "\n",
        "# Paso 6: Obtener los coeficientes del modelo de forma segura\n",
        "params_series = pd.Series(model_robust.params, index=model_robust.model.exog_names)\n",
        "\n",
        "print(\"\\nParámetros del modelo robusto (Entrenamiento):\")\n",
        "print(params_series)\n",
        "\n",
        "# Paso 7: Evaluar el modelo en el conjunto de prueba\n",
        "y_pred_test = model_robust.predict(X_test_const)\n",
        "y_true_test = Y_test\n",
        "\n",
        "r_squared_test = r2_score(y_true_test, y_pred_test)\n",
        "mse_test = mean_squared_error(y_true_test, y_pred_test)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "mae_test = mean_absolute_error(y_true_test, y_pred_test)\n",
        "durbin_watson_stat_test = sm.stats.durbin_watson(model_robust.resid)\n",
        "\n",
        "# Mostrar las métricas de evaluación en el conjunto de prueba\n",
        "print(\"\\nMétricas de Evaluación del Modelo en el Conjunto de Prueba:\")\n",
        "print(f\"R²: {r_squared_test:.4f}\")\n",
        "print(f\"MSE: {mse_test:.4f}\")\n",
        "print(f\"RMSE: {rmse_test:.4f}\")\n",
        "print(f\"MAE: {mae_test:.4f}\")\n",
        "print(f\"Durbin-Watson: {durbin_watson_stat_test:.4f}\")\n",
        "\n",
        "# Paso 8: Test de Breusch-Pagan en el conjunto de entrenamiento\n",
        "bp_test = het_breuschpagan(model_robust.resid, model_robust.model.exog)\n",
        "bp_test_results = {\n",
        "    'Lagrange multiplier statistic': bp_test[0],\n",
        "    'p-value': bp_test[1],\n",
        "    'f-value': bp_test[2],\n",
        "    'f p-value': bp_test[3]\n",
        "}\n",
        "print(\"\\nResultados de la prueba de Breusch-Pagan (Entrenamiento):\")\n",
        "for key, value in bp_test_results.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "# Test de White en el conjunto de entrenamiento\n",
        "white_test = het_white(model_robust.resid, model_robust.model.exog)\n",
        "white_test_results = {\n",
        "    'Test Statistic': white_test[0],\n",
        "    'Test Statistic p-value': white_test[1],\n",
        "    'F-Statistic': white_test[2],\n",
        "    'F-Statistic p-value': white_test[3]\n",
        "}\n",
        "print(\"\\nResultados de la prueba de White (Entrenamiento):\")\n",
        "for key, value in white_test_results.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "# Paso 9: Obtener los coeficientes del modelo de forma segura\n",
        "required_params = ['const', 'actual_price']\n",
        "missing_params = [param for param in required_params if param not in params_series.index]\n",
        "\n",
        "if not missing_params:\n",
        "    intercept = params_series['const']\n",
        "    slope = params_series['actual_price']\n",
        "\n",
        "    # Formatear la ecuación del modelo\n",
        "    equation = f\"I = {slope:.3f}X + {intercept:.3f}\"\n",
        "    interpretation = f\"Esto indica que por cada incremento de 1 Euro en el precio real, el precio con descuento aumenta en {slope:.3f} Euros.\"\n",
        "\n",
        "    # Mostrar la ecuación del modelo\n",
        "    print(f\"\\n{equation}. {interpretation}\")\n",
        "else:\n",
        "    print(f\"\\nError: Los siguientes parámetros no se encontraron en el modelo: {missing_params}\")\n",
        "    print(\"Parámetros disponibles:\")\n",
        "    print(params_series)\n",
        "    raise KeyError(f\"Parámetros faltantes: {missing_params}\")\n",
        "\n",
        "# Paso 10: Guardar el modelo en disco utilizando pickle\n",
        "filename = 'model.pkl'\n",
        "try:\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump(model_robust, file)\n",
        "    print(f\"\\nModelo guardado en {filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nError al guardar el modelo: {e}\")\n",
        "    raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1SIG8fFbFgr",
        "outputId": "2e80aab3-0d00-4310-977b-1e01c6dcbc75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Número de observaciones en entrenamiento: 1172\n",
            "Número de observaciones en prueba: 293\n",
            "\n",
            "Valores de VIF para cada variable predictora (Entrenamiento):\n",
            "        Feature       VIF\n",
            "0         const  1.253367\n",
            "1  actual_price  1.000000\n",
            "\n",
            "Resumen del modelo de regresión lineal con errores estándar robustos (HC3) - Entrenamiento:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:       discounted_price   R-squared:                       0.927\n",
            "Model:                            OLS   Adj. R-squared:                  0.927\n",
            "Method:                 Least Squares   F-statistic:                     1191.\n",
            "Date:                Sat, 02 Nov 2024   Prob (F-statistic):          1.53e-180\n",
            "Time:                        13:41:59   Log-Likelihood:                -5304.8\n",
            "No. Observations:                1172   AIC:                         1.061e+04\n",
            "Df Residuals:                    1170   BIC:                         1.062e+04\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:                  HC3                                         \n",
            "================================================================================\n",
            "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "const           -2.8037      0.788     -3.557      0.000      -4.350      -1.257\n",
            "actual_price     0.6126      0.018     34.505      0.000       0.578       0.647\n",
            "==============================================================================\n",
            "Omnibus:                      387.243   Durbin-Watson:                   2.046\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            29299.734\n",
            "Skew:                           0.591   Prob(JB):                         0.00\n",
            "Kurtosis:                      27.466   Cond. No.                         163.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
            "\n",
            "Parámetros del modelo robusto (Entrenamiento):\n",
            "const          -2.803659\n",
            "actual_price    0.612577\n",
            "dtype: float64\n",
            "\n",
            "Métricas de Evaluación del Modelo en el Conjunto de Prueba:\n",
            "R²: 0.9186\n",
            "MSE: 592.8684\n",
            "RMSE: 24.3489\n",
            "MAE: 9.5791\n",
            "Durbin-Watson: 2.0456\n",
            "\n",
            "Resultados de la prueba de Breusch-Pagan (Entrenamiento):\n",
            "Lagrange multiplier statistic: 294.5699538124542\n",
            "p-value: 5.021472337430937e-66\n",
            "f-value: 392.79125151693853\n",
            "f p-value: 1.3279689289777224e-75\n",
            "\n",
            "Resultados de la prueba de White (Entrenamiento):\n",
            "Test Statistic: 305.9611764589901\n",
            "Test Statistic p-value: 3.6422914437741956e-67\n",
            "F-Statistic: 206.49687147866223\n",
            "F-Statistic p-value: 1.5936711138728988e-77\n",
            "\n",
            "I = 0.613X + -2.804. Esto indica que por cada incremento de 1 Euro en el precio real, el precio con descuento aumenta en 0.613 Euros.\n",
            "\n",
            "Modelo guardado en model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Reporte Final Modelo de Regresión Lineal con errores estándar robustos** para la Predicción del Precio con Descuento\n",
        "\n",
        "## **1. Introducción**\n",
        "\n",
        "Este reporte presenta el desarrollo y evaluación de un **modelo de Regresión Lineal con errores estándar robustos** diseñado para predecir el **precio con descuento** (`discounted_price`) de productos en Amazon. El objetivo principal es optimizar la estrategia de precios mediante la predicción precisa del precio final al consumidor basado en el precio real del producto.\n",
        "\n",
        "**I = 0.613X + -2.804.** Esto indica que por cada incremento de 1 Euro en el precio real, el precio con descuento aumenta en **0.613 Euros.**\n",
        "\n",
        "## **2. Descripción de los Datos**\n",
        "\n",
        "El análisis se realizó utilizando un conjunto de datos que incluye las siguientes variables:\n",
        "\n",
        "- **actual_price**: Precio real del producto en Euros.\n",
        "- **discounted_price**: Precio final del producto después de aplicar el descuento (variable objetivo).\n",
        "\n",
        "**Cantidad de Observaciones:**\n",
        "\n",
        "- **Entrenamiento**: 1,172 observaciones\n",
        "- **Prueba**: 293 observaciones\n",
        "\n",
        "## **3. Selección y División de Variables**\n",
        "\n",
        "Se seleccionó una única variable independiente:\n",
        "\n",
        "- **actual_price**\n",
        "\n",
        "La variable dependiente es:\n",
        "\n",
        "- **discounted_price**\n",
        "\n",
        "El conjunto de datos se dividió en dos subconjuntos:\n",
        "\n",
        "- **Entrenamiento**: 80% (1,172 observaciones)\n",
        "- **Prueba**: 20% (293 observaciones)\n",
        "\n",
        "## **4. Evaluación de Multicolinealidad**\n",
        "\n",
        "Se calculó el **Factor de Inflación de la Varianza (VIF)** para asegurar la ausencia de multicolinealidad significativa entre las variables independientes.\n",
        "\n",
        "| **Feature**      | **VIF**   |\n",
        "|------------------|-----------|\n",
        "| const            | 1.253367  |\n",
        "| actual_price     | 1.000000  |\n",
        "\n",
        "**Interpretación:** Todos los valores de VIF son inferiores a 5, indicando una **ausencia de multicolinealidad significativa** entre las variables independientes.\n",
        "\n",
        "## **5. Ajuste del Modelo de Regresión Lineal**\n",
        "\n",
        "Se ajustó un **modelo de regresión lineal simple** utilizando el método de **Mínimos Cuadrados Ordinarios (OLS)** y se aplicaron **errores estándar robustos (HC3)** para manejar posibles heterocedasticidades.\n",
        "\n",
        "### **Resumen del Modelo de Regresión Lineal con Errores Estándar Robustos (HC3)**\n",
        "\n",
        "```\n",
        "OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:   discounted_price   R-squared:                       0.927\n",
        "Model:            OLS              Adj. R-squared:                  0.927\n",
        "Method:   Least Squares         F-statistic:                     1191.\n",
        "Date:        Sat, 02 Nov 2024    Prob (F-statistic):          1.53e-180\n",
        "Time:                   10:29:50   Log-Likelihood:                -5304.8\n",
        "No. Observations:           1172      AIC:                         1.061e+04\n",
        "Df Residuals:               1170      BIC:                         1.062e+04\n",
        "Df Model:                      1                                        \n",
        "Covariance Type:           HC3                                         \n",
        "===============================================================================\n",
        "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
        "--------------------------------------------------------------------------------\n",
        "const           -2.8037      0.788     -3.557      0.000      -4.350      -1.257\n",
        "actual_price     0.6126      0.018     34.505      0.000       0.578       0.647\n",
        "===============================================================================\n",
        "Omnibus:                      387.243   Durbin-Watson:                   2.046\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            29299.734\n",
        "Skew:                           0.591   Prob(JB):                         0.00\n",
        "Kurtosis:                      27.466   Cond. No.                         163.\n",
        "===============================================================================\n",
        "```\n",
        "\n",
        "## **6. Evaluación del Modelo**\n",
        "\n",
        "### **6.1. Métricas de Evaluación en el Conjunto de Prueba**\n",
        "\n",
        "| **Métrica**       | **Valor**    |\n",
        "|-------------------|--------------|\n",
        "| R²                | 0.9186       |\n",
        "| MSE               | 592.8684     |\n",
        "| RMSE              | 24.3489      |\n",
        "| MAE               | 9.5791       |\n",
        "| Durbin-Watson     | 2.0456       |\n",
        "\n",
        "**Interpretación:**\n",
        "\n",
        "- **R² (0.9186):** El modelo explica aproximadamente el 91.86% de la variabilidad en el precio con descuento, lo que indica un **ajuste muy bueno**.\n",
        "- **MSE (592.8684)** y **RMSE (24.3489):** Representan el error cuadrático medio y su raíz, respectivamente, reflejando la precisión de las predicciones del modelo.\n",
        "- **MAE (9.5791):** Indica que, en promedio, las predicciones del modelo están a aproximadamente 9.58 Euros del valor real.\n",
        "- **Durbin-Watson (2.0456):** Un valor cercano a 2 sugiere **ausencia de autocorrelación** en los residuos.\n",
        "\n",
        "## **7. Diagnóstico del Modelo**\n",
        "\n",
        "Las pruebas realizadas confirman la presencia de **heterocedasticidad** en los residuos. No obstante, el uso de **errores estándar robustos (HC3)** garantiza la validez de las inferencias sobre los coeficientes del modelo.\n",
        "\n",
        "Además, la estadística de **Durbin-Watson** cercana a 2 respalda la integridad del modelo al indicar **ausencia de autocorrelación** en los residuos.\n",
        "\n",
        "## **8. Interpretación de los Resultados**\n",
        "\n",
        "El modelo de regresión lineal simple ajustado muestra una **alta capacidad explicativa** con un **R²** de 0.927 en el conjunto de entrenamiento y 0.9186 en el de prueba. El coeficiente de `actual_price` es **0.6126**, indicando que por cada incremento de 1 Euro en el precio real, el precio con descuento aumenta en aproximadamente **0.613 Euros**.\n",
        "\n",
        "## **9. Conclusiones**\n",
        "\n",
        "El **Modelo 2: Regresión Lineal Simple con una Variable** se considera **eficaz** para predecir el precio con descuento de productos en Amazon debido a los siguientes factores:\n",
        "\n",
        "- **Desempeño Predictivo Superior:** Presenta un alto **R²** tanto en entrenamiento como en prueba, indicando una excelente capacidad explicativa.\n",
        "- **Coeficiente Realista:** El valor de **0.613** para `actual_price` es coherente y facilita la interpretación práctica del modelo.\n",
        "- **Ausencia de Multicolinealidad Significativa:** Los valores de VIF son aceptables, garantizando la estabilidad y confiabilidad de los coeficientes.\n",
        "- **Simplicidad y Facilidad de Implementación:** Un modelo sencillo con una sola variable independiente facilita su implementación y comunicación de resultados.\n",
        "\n",
        
      ],
      "metadata": {
        "id": "ZRqjMOj7k8UF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
